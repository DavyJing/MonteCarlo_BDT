{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy based CART, incuding integration of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarySplit(dataset,feature,value):\n",
    "    matLeft = dataset[dataset[:, feature] <= value]\n",
    "    matRight = dataset[dataset[:, feature] > value]\n",
    "    return matLeft, matRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressLeaf(dataset):\n",
    "    if len(dataset) == 0: return 0\n",
    "    return np.mean(dataset[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getError(dataset,featureIndex,thresholdSamples):\n",
    "    dataset = dataset[dataset[:,featureIndex].argsort()]\n",
    "    tot_sum = sum(dataset[:,-1])\n",
    "    tot_sum_square = sum(dataset[:,-1]*dataset[:,-1])\n",
    "    cur = 0\n",
    "    tmpVariance = float('inf')\n",
    "    tmpIndex = thresholdSamples\n",
    "    for i in range(dataset.shape[0]-thresholdSamples):\n",
    "        cur += dataset[i][-1]\n",
    "        variance = -cur*cur/(i+1)-(tot_sum-cur)*(tot_sum-cur)/(dataset.shape[0]-i-1)\n",
    "        if variance < tmpVariance and i > thresholdSamples:\n",
    "            tmpVariance = variance\n",
    "            tmpIndex = i\n",
    "    return tot_sum_square+tmpVariance, dataset[tmpIndex][featureIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestSplit(dataset,leafType=regressLeaf,threshold=(0,4)):\n",
    "    thresholdErr, thresholdSamples = threshold[0], threshold[1]\n",
    "    if len(set(dataset[:,-1])) == 1 or dataset.shape[0]<=thresholdSamples:\n",
    "        return None,leafType(dataset)\n",
    "    m,n = dataset.shape\n",
    "    Err = float('inf')\n",
    "    bestErr, bestFeatureIndex, bestFeatureValue = np.inf, 0, 0\n",
    "    for featureIndex in range(n-1):\n",
    "        tmpErr, featureValue = getError(dataset,featureIndex,thresholdSamples)\n",
    "        if tmpErr < bestErr:\n",
    "            bestErr,bestFeatureIndex,bestFeatureValue = tmpErr,featureIndex,featureValue\n",
    "    if (Err - bestErr) < thresholdErr:\n",
    "        return None, leafType(dataset)\n",
    "    return bestFeatureIndex,bestFeatureValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCART(dataset,leafType=regressLeaf,threshold=(1,4),depth=5):\n",
    "    if depth==0: return leafType(dataset)\n",
    "    feature,value = chooseBestSplit(dataset,leafType,threshold)\n",
    "    if feature == None: return value\n",
    "    returnTree = {}\n",
    "    returnTree['bestSplitFeature'] = feature\n",
    "    returnTree['bestFeatureValue'] = value\n",
    "    leftSet, rightSet = binarySplit(dataset,feature,value)\n",
    "    returnTree['left'] = createCART(leftSet,leafType,threshold,depth-1)\n",
    "    returnTree['right'] = createCART(rightSet,leafType,threshold,depth-1)\n",
    "    return returnTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isTree(obj):\n",
    "        return (type(obj).__name__=='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressEvaluation(tree,inputData):\n",
    "    return float(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valuePredict(tree,inputData,modelEval = regressEvaluation):\n",
    "        if not isTree(tree): return modelEval(tree,inputData)\n",
    "        if inputData[tree['bestSplitFeature']] <= tree['bestFeatureValue']:\n",
    "                if isTree(tree['left']):\n",
    "                        return valuePredict(tree['left'],inputData,modelEval)\n",
    "                else:\n",
    "                        return modelEval(tree['left'],inputData)\n",
    "        else:\n",
    "                if isTree(tree['right']):\n",
    "                        return valuePredict(tree['right'],inputData,modelEval)\n",
    "                else:\n",
    "                        return modelEval(tree['right'],inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree,testData,modelEval=regressEvaluation):\n",
    "        m = len(testData)\n",
    "        yHat = []\n",
    "        for i in range(m):\n",
    "                yHat += [valuePredict(tree,testData[i],modelEval)]\n",
    "        return np.array(yHat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_evaluator(tree,interval):\n",
    "    if (type(tree).__name__!='dict'):\n",
    "# check if it's nan\n",
    "        if tree!= tree:\n",
    "            return 0\n",
    "        res = tree\n",
    "        for i in interval:\n",
    "            res *= (interval[i][1] - interval[i][0])\n",
    "#        print(interval,tree)\n",
    "        return res\n",
    "    else:\n",
    "        axis = tree['bestSplitFeature']\n",
    "        val = tree['bestFeatureValue']\n",
    "        left_interval = {key:[i for i in interval[key]] for key in interval}\n",
    "        right_interval = {key:[i for i in interval[key]] for key in interval}\n",
    "        if axis in interval:\n",
    "            left_interval[axis][1] = min(left_interval[axis][1],val)\n",
    "            right_interval[axis][0] = max(right_interval[axis][0],val)\n",
    "        else:\n",
    "            left_interval[axis] = [0,val]\n",
    "            right_interval[axis] = [val,1]\n",
    "        return tree_evaluator(tree['left'],left_interval) + tree_evaluator(tree['right'],right_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Integrand(grid):\n",
    "    res = []\n",
    "    for var in grid:\n",
    "        x,y,z,w,a,b = var\n",
    "        res += [x+y-z+np.exp(w)-np.tan(a)+np.cos(b)]\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.random.rand(10000,6)\n",
    "vals = Integrand(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(len(grid)):\n",
    "    tmp = grid[i].tolist() + [vals[i]]\n",
    "    dataset += [tmp]\n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1765301815746734\n",
      "CPU times: user 471 ms, sys: 955 Âµs, total: 472 ms\n",
      "Wall time: 470 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regressTree = createCART(dataset,depth=tree_depth)\n",
    "y_hat = predict(regressTree,grid)\n",
    "\n",
    "\n",
    "res = 0\n",
    "for i in range(len(y_hat)):\n",
    "    res += (y_hat[i] - vals[i])**2\n",
    "print(res/len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4442215204366615"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_evaluator(regressTree,{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17781692626550416\n",
      "CPU times: user 34.1 ms, sys: 1 ms, total: 35.1 ms\n",
      "Wall time: 33.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regressor = DecisionTreeRegressor(random_state=0,max_depth=tree_depth)\n",
    "regressor.fit(grid,vals)\n",
    "\n",
    "y_hat = regressor.predict(grid)\n",
    "res = 0\n",
    "for i in range(len(y_hat)):\n",
    "    res += (y_hat[i] - vals[i])**2\n",
    "print(res/len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_integrate(estimator):\n",
    "    feature = estimator.tree_.feature\n",
    "    threshold = estimator.tree_.threshold\n",
    "    value = estimator.tree_.value.flatten()\n",
    "    return sk_tree_evalutaor(feature,threshold,value,{})\n",
    "\n",
    "def sk_tree_evalutaor(feature,threshold,value,interval):\n",
    "    if feature[0] < 0:\n",
    "        res = value[0]\n",
    "        for i in interval:\n",
    "            res *= (interval[i][1]-interval[i][0])\n",
    "        return res\n",
    "    else:\n",
    "        axis = feature[0]\n",
    "        val = threshold[0]\n",
    "        left_interval = {key:[i for i in interval[key]] for key in interval}\n",
    "        right_interval = {key:[i for i in interval[key]] for key in interval}\n",
    "        if axis in interval:\n",
    "            left_interval[axis][1] = min(left_interval[axis][1],val)\n",
    "            right_interval[axis][0] = max(right_interval[axis][0],val)\n",
    "        else:\n",
    "            left_interval[axis] = [0,val]\n",
    "            right_interval[axis] = [val,1]\n",
    "        if len(feature) == 3:\n",
    "            loc = 2\n",
    "        else:\n",
    "            for i in range(1,len(feature)):\n",
    "                if check_full(feature[1:i]) and check_full(feature[i:]):\n",
    "                    loc = i\n",
    "                    break\n",
    "        left = sk_tree_evalutaor(feature[1:loc],threshold[1:loc],value[1:loc],left_interval)\n",
    "        right = sk_tree_evalutaor(feature[loc:],threshold[loc:],value[loc:],right_interval)\n",
    "        return left+right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_full(tree_node):\n",
    "    if len(tree_node) == 1 and tree_node[0] == -2:\n",
    "        return True\n",
    "    stack = []\n",
    "    for i in tree_node:\n",
    "        if i >= 0: \n",
    "            stack += [i]\n",
    "        else:\n",
    "            if len(stack) >=1 and stack[-1] == -1:\n",
    "                stack[-1] = -2\n",
    "            elif len(stack) >= 1:\n",
    "                stack[-1] = -1\n",
    "        while len(stack) > 1 and stack[-1]==-2:\n",
    "            if stack[-2] != -1:\n",
    "                stack[-2] = -1\n",
    "            else:\n",
    "                stack[-2] = -2\n",
    "            stack.pop()\n",
    "    return stack == [-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4402987242789997"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_integrate(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeRegressor' object has no attribute 'export_graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-437-341204b90d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeRegressor' object has no attribute 'export_graphviz'"
     ]
    }
   ],
   "source": [
    "import pydotplus\n",
    "dot_data = tree.export_graphviz(regressor, out_file=None)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy based BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BDT(dataset,depth=2,n_est=10,lr=0.1):\n",
    "    res = []\n",
    "    running_dataset = np.copy(dataset)\n",
    "    residue = np.copy(dataset)\n",
    "    for _ in range(n_est):\n",
    "        new_tree = createCART(running_dataset,depth=depth)\n",
    "        y_hat = predict(new_tree,dataset[:,:-1])\n",
    "        residue[:,-1] -= y_hat\n",
    "        running_dataset[:,-1] = residue[:,-1]*lr\n",
    "        res += [new_tree]\n",
    "        if _ % (n_est//10) == 0:\n",
    "            print('{} estimator trained'.format(_))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 estimator trained\n",
      "1 estimator trained\n",
      "2 estimator trained\n",
      "3 estimator trained\n",
      "4 estimator trained\n",
      "5 estimator trained\n",
      "6 estimator trained\n",
      "7 estimator trained\n",
      "8 estimator trained\n",
      "9 estimator trained\n"
     ]
    }
   ],
   "source": [
    "boosted_tree = BDT(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22773115694484686\n"
     ]
    }
   ],
   "source": [
    "y_hat = sum([predict(tree,grid) for tree in boosted_tree])\n",
    "res = 0\n",
    "for i in range(len(y_hat)):\n",
    "    res += (y_hat[i] - vals[i])**2\n",
    "print(res/len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4393687841237144"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([tree_evaluator(tree,{}) for tree in boosted_tree if tree_evaluator(tree,{})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"screen.out\", \"r\")\n",
    "lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in lines[:-7]:\n",
    "    nums = line.split()\n",
    "    if len(nums) == 12:\n",
    "        nums = [float(num) for num in nums]\n",
    "        data += [nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.28871e-01, 3.64784e-01, 5.13401e-01, ..., 1.63006e-02,\n",
       "        2.42887e-01, 1.07647e+04],\n",
       "       [1.37232e-01, 8.04177e-01, 1.56679e-01, ..., 8.39112e-01,\n",
       "        6.12640e-01, 0.00000e+00],\n",
       "       [2.96032e-01, 6.37552e-01, 5.24287e-01, ..., 4.00229e-01,\n",
       "        8.91529e-01, 1.63409e+04],\n",
       "       ...,\n",
       "       [6.01785e-01, 7.35004e-02, 3.37025e-01, ..., 2.73972e-01,\n",
       "        7.38237e-01, 7.45169e+01],\n",
       "       [4.73995e-01, 6.29764e-02, 3.57536e-01, ..., 2.87283e-01,\n",
       "        6.27453e-01, 0.00000e+00],\n",
       "       [8.01884e-01, 1.79018e-01, 2.66675e-01, ..., 6.09341e-01,\n",
       "        8.06570e-01, 0.00000e+00]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 estimator trained\n",
      "1 estimator trained\n",
      "2 estimator trained\n",
      "3 estimator trained\n",
      "4 estimator trained\n",
      "5 estimator trained\n",
      "6 estimator trained\n",
      "7 estimator trained\n",
      "8 estimator trained\n",
      "9 estimator trained\n"
     ]
    }
   ],
   "source": [
    "boosted_tree = BDT(data,depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8733.35587401102"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([tree_evaluator(tree,{}) for tree in boosted_tree if tree_evaluator(tree,{})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8734.13274208207"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_evaluator(boosted_tree[0],{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bestSplitFeature': 5,\n",
       " 'bestFeatureValue': 0.103537,\n",
       " 'left': {'bestSplitFeature': 5,\n",
       "  'bestFeatureValue': 0.0648196,\n",
       "  'left': 611.0241823982898,\n",
       "  'right': 4148.542707058089},\n",
       " 'right': {'bestSplitFeature': 5,\n",
       "  'bestFeatureValue': 0.894761,\n",
       "  'left': 10521.312480372719,\n",
       "  'right': 1987.7675159590021}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_tree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_GBDT_numpy(data_set,ratio):\n",
    "    x = data_set[:,:-1]\n",
    "    y = data_set[:,-1]\n",
    "    split = int(ratio * x.shape[0])\n",
    "    x_train, x_test, y_train, y_test = x[:split,:], x[split:,:] , y[:split], y[split:]\n",
    "    \n",
    "    boosted_tree = BDT(data_set[:split,:],depth=5,n_est=300,lr=0.2)\n",
    "    y_hat = sum([predict(tree,x_test) for tree in boosted_tree])\n",
    "    \n",
    "    residue = y_test - y_hat\n",
    "    residue_val = sum(residue)/len(residue)\n",
    "    err = math.sqrt((sum(residue*residue)/len(residue)-residue_val*residue_val)/len(residue))\n",
    "    print(\"Current error is {}, number of calls of integrand is {}\".format(err,len(residue)))\n",
    "    return err, residue_val+sum([tree_evaluator(tree,{}) for tree in boosted_tree if tree_evaluator(tree,{})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 estimator trained\n",
      "30 estimator trained\n",
      "60 estimator trained\n",
      "90 estimator trained\n",
      "120 estimator trained\n",
      "150 estimator trained\n",
      "180 estimator trained\n",
      "210 estimator trained\n",
      "240 estimator trained\n",
      "270 estimator trained\n",
      "Current error is 2.6592227459981914, number of calls of integrand is 162000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.6592227459981914, 8724.503852596315)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC_GBDT_numpy(data,ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BDT_sklearn(dataset,depth=2,n_est=1000,lr=0.1):\n",
    "    res = []\n",
    "    running_dataset = np.copy(dataset)\n",
    "    residue = np.copy(dataset)\n",
    "    for _ in range(n_est):\n",
    "        regressor = DecisionTreeRegressor(random_state=0,max_depth=depth)\n",
    "        regressor.fit(running_dataset[:,:-1],running_dataset[:,-1])\n",
    "\n",
    "        y_hat = regressor.predict(running_dataset[:,:-1])\n",
    "        residue[:,-1] -= y_hat\n",
    "        running_dataset[:,-1] = residue[:,-1]*lr\n",
    "        res += [regressor]\n",
    "        if _ % (n_est//10) == 0:\n",
    "            print('{} estimator trained'.format(_))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 estimator trained\n",
      "100 estimator trained\n",
      "200 estimator trained\n",
      "300 estimator trained\n",
      "400 estimator trained\n",
      "500 estimator trained\n",
      "600 estimator trained\n",
      "700 estimator trained\n",
      "800 estimator trained\n",
      "900 estimator trained\n"
     ]
    }
   ],
   "source": [
    "boosted_tree = BDT_sklearn(data[:10000,:],depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_GBDT(data_set,ratio):\n",
    "    x = data_set[:,:-1]\n",
    "    y = data_set[:,-1]\n",
    "    split = int(ratio * x.shape[0])\n",
    "    x_train, x_test, y_train, y_test = x[:split,:], x[split:,:] , y[:split], y[split:]\n",
    "    boosted_tree = BDT_sklearn(data_set[:split,:],depth=6,n_est=100,lr=0.4)\n",
    "    y_hat = sum([tree.predict(x_test) for tree in boosted_tree])\n",
    "\n",
    "    residue = y_test - y_hat\n",
    "    residue_val = sum(residue)/len(residue)\n",
    "    err = math.sqrt((sum(residue*residue)/len(residue)-residue_val*residue_val)/len(residue))\n",
    "    print(\"Current error is {}, number of calls of integrand is {}\".format(err,len(residue)))\n",
    "    return err, residue_val+sum([tree_integrate(tree) for tree in boosted_tree if tree_integrate(tree)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 3.402054312315024, number of calls of integrand is 192375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.402054312315024, 8725.176081504564)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC_GBDT(data,ratio=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 4.573727758748284, number of calls of integrand is 200475\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 4.095687504562164, number of calls of integrand is 198450\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 3.7752352477250817, number of calls of integrand is 196425\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 3.6402077753144853, number of calls of integrand is 194400\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 3.402054312315024, number of calls of integrand is 192375\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 3.3271979064819823, number of calls of integrand is 190350\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 3.1620743785811634, number of calls of integrand is 188325\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 3.218737544870335, number of calls of integrand is 186300\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.9072005650666664, number of calls of integrand is 184275\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.9876372740506096, number of calls of integrand is 182250\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 3.0560566837489467, number of calls of integrand is 180225\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.981939551231462, number of calls of integrand is 178200\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.924821007196003, number of calls of integrand is 176175\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.8939731807842612, number of calls of integrand is 174150\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.8393526427989544, number of calls of integrand is 172125\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.845095383359529, number of calls of integrand is 170100\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.8714389597874166, number of calls of integrand is 168075\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.86386922394576, number of calls of integrand is 166050\n",
      "0 estimator trained\n",
      "10 estimator trained\n",
      "20 estimator trained\n",
      "30 estimator trained\n",
      "40 estimator trained\n",
      "50 estimator trained\n",
      "60 estimator trained\n",
      "70 estimator trained\n",
      "80 estimator trained\n",
      "90 estimator trained\n",
      "Current error is 2.879205828930827, number of calls of integrand is 164025\n"
     ]
    }
   ],
   "source": [
    "rat = [0.01* i for i in range(1,20)]\n",
    "for per in rat:\n",
    "    MC_GBDT(data,ratio=per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
